from dotenv import load_dotenv

load_dotenv()

import os
import streamlit as st


from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage


# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="å°‚é–€å®¶åˆ‡æ›¿ LLMã‚¢ãƒ—ãƒªï¼ˆæ—…è¡Œ/æ–™ç†ï¼‰", page_icon="ğŸ§­", layout="centered")

# --- ç”»é¢ï¼šã‚¢ãƒ—ãƒªã®æ¦‚è¦ã¨æ“ä½œæ–¹æ³•ï¼ˆæ˜ç¤ºè¡¨ç¤ºï¼‰ ---
st.title("ğŸ§­ å°‚é–€å®¶åˆ‡æ›¿ LLMã‚¢ãƒ—ãƒªï¼ˆLangChain + Streamlitï¼‰")
st.markdown(
    """
**æ¦‚è¦**  
- å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’1ã¤è¨˜å…¥ã—ã€ãƒ©ã‚¸ã‚ªã§ **ã€Œæ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€** ã¾ãŸã¯ **ã€Œæ–™ç†ç ”ç©¶å®¶ã€** ã‚’é¸ã¶ã¨ã€  
  é¸ã‚“ã å°‚é–€å®¶ã¨ã—ã¦ LLM ãŒå›ç­”ã—ã¾ã™ã€‚  

**æ“ä½œæ–¹æ³•**  
1. ä¸‹ã®ãƒ©ã‚¸ã‚ªã§ **å°‚é–€å®¶ã®ç¨®é¡** ã‚’é¸æŠ  
2. å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã« **è³ªå•ã‚„ä¾é ¼å†…å®¹** ã‚’è¨˜å…¥  
3. **ã€Œé€ä¿¡ã€** ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€ä¸‹ã« LLM ã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™

**æ³¨æ„äº‹é …**  
- ä¼šè©±å±¥æ­´ã¯ä¿æŒã—ãªã„å˜ç™ºè³ªå•ã‚¹ã‚¿ã‚¤ãƒ«ã§ã™ã€‚  
- æ©Ÿå¯†æƒ…å ±ã®å…¥åŠ›ã¯é¿ã‘ã¦ãã ã•ã„ã€‚å›ç­”ã¯å‚è€ƒæƒ…å ±ã¨ã—ã¦ã”åˆ©ç”¨ãã ã•ã„ã€‚
"""
)

# --- å°‚é–€å®¶ã® SystemMessage å®šç¾©ï¼ˆé¸æŠå€¤ã«å¿œã˜ã¦åˆ‡æ›¿ï¼‰ ---
SYSTEM_MESSAGES = {
    "æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼": (
        "ã‚ãªãŸã¯æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã§ã™ã€‚äºˆç®—ãƒ»ç›®çš„ãƒ»å­£ç¯€ãƒ»ç§»å‹•æ‰‹æ®µãªã©ã‚’è€ƒæ…®ã—ã€"
        "åˆå¿ƒè€…ã«ã‚‚ã‚ã‹ã‚Šã‚„ã™ãã€1æ—¥ã®è¡Œç¨‹ã‚’ç®‡æ¡æ›¸ãã§ç¤ºã—ãªãŒã‚‰ã€"
        "ãŠã™ã™ã‚ã‚¹ãƒãƒƒãƒˆã®ç°¡å˜ãªç†ç”±ã‚„ä»£æ›¿æ¡ˆã‚‚æ·»ãˆã¦ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
    ),
    "æ–™ç†ç ”ç©¶å®¶": (
        "ã‚ãªãŸã¯å®¶åº­æ–™ç†ã®æ–™ç†ç ”ç©¶å®¶ã§ã™ã€‚å°‘ãªã„ææ–™ã§ã‚‚ä½œã‚Œã‚‹ã‚ˆã†å·¥å¤«ã—ã€"
        "æ‰‹é †ã‚’ç•ªå·ä»˜ãã§ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚ä¸‹æº–å‚™ã€ç«åŠ æ¸›ã€æ™‚é–“ã®ç›®å®‰ã€"
        "ä»£æ›¿é£Ÿæã‚„æ™‚çŸ­ã®ã‚³ãƒ„ã‚‚å¿…è¦ã«å¿œã˜ã¦ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
    ),
}

# --- è¦ä»¶ï¼šå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨é¸æŠå€¤ã‚’å¼•æ•°ã«å–ã‚Šã€LLMå›ç­”ã‚’æˆ»ã™é–¢æ•° ---
def generate_response(input_text: str, selected_role: str) -> str:
    """
    Args:
        input_text (str): ç”»é¢ã®å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰å—ã‘å–ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        selected_role (str): ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®é¸æŠå€¤ï¼ˆ'æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼' ã¾ãŸã¯ 'æ–™ç†ç ”ç©¶å®¶'ï¼‰

    Returns:
        str: LLM ã‹ã‚‰ã®å›ç­”ãƒ†ã‚­ã‚¹ãƒˆ
    """
    if selected_role not in SYSTEM_MESSAGES:
        raise ValueError("ä¸æ­£ãªé¸æŠå€¤ã§ã™ã€‚'æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼' ã¾ãŸã¯ 'æ–™ç†ç ”ç©¶å®¶' ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")


    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)  
    messages = [
        SystemMessage(content=SYSTEM_MESSAGES[selected_role]),
        HumanMessage(content=input_text),
    ]
    result = llm.invoke(messages)  # AIMessage ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    return result.content    # å›ç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™

# --- APIã‚­ãƒ¼å­˜åœ¨ãƒã‚§ãƒƒã‚¯ ---
if not os.getenv("OPENAI_API_KEY"):
    st.warning("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ã« `OPENAI_API_KEY=...` ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚")

# --- UIï¼ˆãƒ©ã‚¸ã‚ªï¼‹å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã¯1ã¤ï¼‰ ---
role = st.radio(
    "LLM ã«æŒ¯ã‚‹èˆã‚ã›ã‚‹å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
    options=["æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼", "æ–™ç†ç ”ç©¶å®¶"],
    horizontal=True,
)

with st.form(key="main_form", clear_on_submit=False):
    user_text = st.text_area(
        "å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼ˆè³ªå•ã‚„ä¾é ¼å†…å®¹ã‚’1ã¤è¨˜å…¥ã—ã¦ãã ã•ã„ï¼‰",
        height=160,
        placeholder="ä¾‹ï¼š2ä¸‡å††ä»¥å†…ã§é•·é‡ç™ºã®1æ³Š2æ—¥æ¸©æ³‰æ—…è¡Œãƒ—ãƒ©ãƒ³ã‚’è€ƒãˆã¦ã€‚é›»è»Šç§»å‹•ã€æ··é›‘ã¯é¿ã‘ãŸã„ã§ã™ã€‚",
    )
    submitted = st.form_submit_button("é€ä¿¡", type="primary")

# --- å®Ÿè¡Œã¨è¡¨ç¤º ---
if submitted:
    if not user_text.strip():
        st.warning("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚")
    elif not os.getenv("OPENAI_API_KEY"):
        st.error("OPENAI_API_KEY ãŒæœªè¨­å®šã®ãŸã‚ã€å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
    else:
        with st.spinner("LLM ã«å•ã„åˆã‚ã›ä¸­..."):
            try:
                answer = generate_response(user_text.strip(), role)
                st.markdown("### å›ç­”")
                st.markdown(answer)
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{e}")

